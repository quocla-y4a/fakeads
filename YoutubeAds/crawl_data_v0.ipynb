{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WPadQIsAS9b"
      },
      "source": [
        "## Topic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8DUvQXzAeAN",
        "outputId": "1681b032-1703-4779-a5fe-2db061f129a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: youtube_transcript_api in c:\\users\\quocla\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.2.3)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in c:\\users\\quocla\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from youtube_transcript_api) (0.7.1)\n",
            "Requirement already satisfied: requests in c:\\users\\quocla\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from youtube_transcript_api) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\quocla\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->youtube_transcript_api) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\quocla\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->youtube_transcript_api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\quocla\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->youtube_transcript_api) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\quocla\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->youtube_transcript_api) (2025.8.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "pip install youtube_transcript_api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "geKb8wOSAcD-"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import csv\n",
        "import os\n",
        "from datetime import datetime\n",
        "f   rom googleapiclient.discovery import build\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e6e9899",
        "outputId": "6877b69c-499e-486d-fffb-9b4f85fda420"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      4\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "EMYuG3GWAjc-"
      },
      "outputs": [],
      "source": [
        "# CONFIG\n",
        "# ========================\n",
        "API_KEY = \"AIzaSyDkFs6pVdkR871rDmea_SOyFc5qlmz92NI\"\n",
        "VIDEO_ID = \"bPsAKX1ocTs\"\n",
        "PLAYLIST_ID = \"PLqFfyQGXEX5rC-BKJpLY67PT3lDh684M0\"\n",
        "\n",
        "# Playlist Qu·∫£ng c√°o Ph√°t ki·∫øm\n",
        "# https://www.youtube.com/watch?v=IM8lTK9Jbco&list=PLqFfyQGXEX5rC-BKJpLY67PT3lDh684M0\n",
        "\n",
        "# Yakult Video: https://www.youtube.com/watch?v=bPsAKX1ocTs\n",
        "# y-HLsEIyDjI\n",
        "\n",
        "# https://www.youtube.com/watch?v=cuoM9amPt-I&list=PLGeL0tgf1NADxLzzVARqadY1H-fNXXkDw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fpnmNruGKQX"
      },
      "source": [
        "### get by video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QSKFyJ7yAmDK"
      },
      "outputs": [],
      "source": [
        "# FUNCTION: get metadata video\n",
        "# ========================\n",
        "def get_video_info(api_key, video_id):\n",
        "    youtube = build(\"youtube\", \"v3\", developerKey=api_key)\n",
        "\n",
        "    request = youtube.videos().list(\n",
        "        part=\"snippet,statistics,contentDetails,status,player,recordingDetails,topicDetails\",\n",
        "        id=video_id\n",
        "    )\n",
        "    response = request.execute()\n",
        "    if not response[\"items\"]:\n",
        "        return None\n",
        "    return response[\"items\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AhMlSaXxApcv"
      },
      "outputs": [],
      "source": [
        "# FUNCTION: get transcript\n",
        "# ========================\n",
        "def get_transcript(video_id):\n",
        "    try:\n",
        "        transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=['en', 'vi'])\n",
        "        text = \" \".join([line[\"text\"] for line in transcript])\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qdi6Kr_AXx8",
        "outputId": "ce58f2dd-d2db-49a0-e19e-862d8f1189c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Saved data in folder: data\\2025-10-21\n"
          ]
        }
      ],
      "source": [
        "# MAIN PIPELINE\n",
        "# ========================\n",
        "def main():\n",
        "    # 1. get metadata\n",
        "    video_info = get_video_info(API_KEY, VIDEO_ID)\n",
        "    if not video_info:\n",
        "        print(\"‚ùå There is no video.\")\n",
        "        return\n",
        "\n",
        "    snippet = video_info[\"snippet\"]\n",
        "    statistics = video_info.get(\"statistics\", {})\n",
        "    content_details = video_info.get(\"contentDetails\", {})\n",
        "\n",
        "    data = {\n",
        "        \"video_id\": VIDEO_ID,\n",
        "        \"title\": snippet.get(\"title\"),\n",
        "        \"description\": snippet.get(\"description\"),\n",
        "        \"publishedAt\": snippet.get(\"publishedAt\"),\n",
        "        \"channelId\": snippet.get(\"channelId\"),\n",
        "        \"channelTitle\": snippet.get(\"channelTitle\"),\n",
        "        \"tags\": snippet.get(\"tags\", []),\n",
        "        \"viewCount\": statistics.get(\"viewCount\"),\n",
        "        \"likeCount\": statistics.get(\"likeCount\"),\n",
        "        \"commentCount\": statistics.get(\"commentCount\"),\n",
        "        \"duration\": content_details.get(\"duration\"),\n",
        "        \"caption\": content_details.get(\"caption\"),\n",
        "    }\n",
        "\n",
        "    # 2. get transcript\n",
        "    transcript_text = get_transcript(VIDEO_ID)\n",
        "    data[\"transcript\"] = transcript_text if transcript_text else \"No transcript available\"\n",
        "\n",
        "    # Create folder to save data by date\n",
        "    # ========================\n",
        "    today = datetime.today().strftime(\"%Y-%m-%d\")\n",
        "    save_dir = os.path.join(\"data\", today)\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    json_path = os.path.join(save_dir, \"video_data.json\")\n",
        "    csv_path = os.path.join(save_dir, \"video_data.csv\")\n",
        "\n",
        "    # Save JSON\n",
        "    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "    # Save CSV\n",
        "    if data:\n",
        "        keys = data.keys()\n",
        "        with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "            writer = csv.DictWriter(f, fieldnames=keys)\n",
        "            writer.writeheader()\n",
        "            writer.writerow(data)\n",
        "\n",
        "    print(f\"‚úÖ Saved data in folder: {save_dir}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "278b3e2d"
      },
      "outputs": [],
      "source": [
        "# Specify the destination folder in your Google Drive\n",
        "drive_save_dir = os.path.join('/content/drive/My Drive/', save_dir)\n",
        "\n",
        "# Create the directory in Google Drive if it doesn't exist\n",
        "os.makedirs(drive_save_dir, exist_ok=True)\n",
        "\n",
        "# Copy the saved files to Google Drive\n",
        "shutil.copy(json_path, drive_save_dir)\n",
        "shutil.copy(csv_path, drive_save_dir)\n",
        "\n",
        "print(f\"‚úÖ Copied data to Google Drive folder: {drive_save_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Py2hycfOGG86"
      },
      "source": [
        "### get by playlists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "BZL4mYMfGFGY"
      },
      "outputs": [],
      "source": [
        "# FUNCTION: get videoId in playlist\n",
        "# ========================\n",
        "def get_videos_from_playlist(api_key, playlist_id):\n",
        "    youtube = build(\"youtube\", \"v3\", developerKey=api_key)\n",
        "    videos = []\n",
        "    next_page_token = None\n",
        "\n",
        "    while True:\n",
        "        request = youtube.playlistItems().list(\n",
        "            part=\"contentDetails\",\n",
        "            playlistId=playlist_id,\n",
        "            maxResults=50,\n",
        "            pageToken=next_page_token\n",
        "        )\n",
        "        response = request.execute()\n",
        "\n",
        "        for item in response[\"items\"]:\n",
        "            videos.append(item[\"contentDetails\"][\"videoId\"])\n",
        "\n",
        "        next_page_token = response.get(\"nextPageToken\")\n",
        "        if not next_page_token:\n",
        "            break\n",
        "    return videos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "AOJ75BUMImsj"
      },
      "outputs": [],
      "source": [
        "# FUNCTION: get metadata video\n",
        "# ========================\n",
        "def get_video_info(api_key, video_id):\n",
        "    youtube = build(\"youtube\", \"v3\", developerKey=api_key)\n",
        "    request = youtube.videos().list(\n",
        "        part=\"snippet,statistics,contentDetails,status\",\n",
        "        id=video_id\n",
        "    )\n",
        "    response = request.execute()\n",
        "    if not response[\"items\"]:\n",
        "        return None\n",
        "    return response[\"items\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "7ShDYmdNIu_-"
      },
      "outputs": [],
      "source": [
        "# FUNCTION: get transcript\n",
        "# ========================\n",
        "def get_transcript(video_id):\n",
        "    try:\n",
        "        transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=['en', 'vi'])\n",
        "        text = \" \".join([line[\"text\"] for line in transcript])\n",
        "        return text\n",
        "    except:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "import time\n",
        "\n",
        "def get_video_comments(api_key, video_id, max_results=100):\n",
        "    # Get all comments\n",
        "    comments = []\n",
        "    base_url = \"https://www.googleapis.com/youtube/v3/commentThreads\"\n",
        "    params = {\n",
        "        \"part\": \"snippet,replies\",\n",
        "        \"videoId\": video_id,\n",
        "        \"maxResults\": max_results,\n",
        "        \"textFormat\": \"plainText\",\n",
        "        \"key\": api_key\n",
        "    }\n",
        "\n",
        "    while True:\n",
        "        response = requests.get(base_url, params=params)\n",
        "        if response.status_code != 200:\n",
        "            print(f\"‚ùå Error fetching comments for {video_id}: {response.text}\")\n",
        "            break\n",
        "\n",
        "        data = response.json()\n",
        "\n",
        "        for item in data.get(\"items\", []):\n",
        "            top_comment_snippet = item[\"snippet\"][\"topLevelComment\"][\"snippet\"]\n",
        "            top_comment = {\n",
        "                \"author\": top_comment_snippet.get(\"authorDisplayName\"),\n",
        "                \"text\": top_comment_snippet.get(\"textDisplay\"),\n",
        "                \"likeCount\": top_comment_snippet.get(\"likeCount\"),\n",
        "                \"publishedAt\": top_comment_snippet.get(\"publishedAt\"),\n",
        "                \"replies\": []\n",
        "            }\n",
        "\n",
        "            # Get replies\n",
        "            replies = item.get(\"replies\", {}).get(\"comments\", [])\n",
        "            for reply in replies:\n",
        "                reply_snippet = reply[\"snippet\"]\n",
        "                top_comment[\"replies\"].append({\n",
        "                    \"author\": reply_snippet.get(\"authorDisplayName\"),\n",
        "                    \"text\": reply_snippet.get(\"textDisplay\"),\n",
        "                    \"likeCount\": reply_snippet.get(\"likeCount\"),\n",
        "                    \"publishedAt\": reply_snippet.get(\"publishedAt\"),\n",
        "                })\n",
        "\n",
        "            comments.append(top_comment)\n",
        "\n",
        "        # Next page\n",
        "        if \"nextPageToken\" in data:\n",
        "            params[\"pageToken\"] = data[\"nextPageToken\"]\n",
        "            time.sleep(0.3)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return comments\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrAKsK-FI2jf",
        "outputId": "2f6b729d-111a-4fc6-ab2b-3172444e63f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîπ Found 49 video in playlist\n",
            "‚û°Ô∏è Crawl video 1/49: IM8lTK9Jbco\n",
            "‚ö†Ô∏è Kh√¥ng c√≥ caption ch√≠nh th·ª©c, chuy·ªÉn sang Whisper...\n"
          ]
        },
        {
          "ename": "HTTPError",
          "evalue": "HTTP Error 400: Bad Request",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[17], line 96\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;66;03m# # Save JSON\u001b[39;00m\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# with open(\"playlist_data.json\", \"w\", encoding=\"utf-8\") as f:\u001b[39;00m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;66;03m#     json.dump(all_data, f, ensure_ascii=False, indent=4)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     92\u001b[0m \n\u001b[0;32m     93\u001b[0m     \u001b[38;5;66;03m# print(f\"‚úÖ Copied data to Google Drive folder: {drive_save_dir}\")\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[17], line 38\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvideo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: vid,\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m: snippet\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcaption\u001b[39m\u001b[38;5;124m\"\u001b[39m: content_details\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcaption\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     33\u001b[0m }\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# transcript_text = get_transcript(vid)\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# data[\"transcript\"] = transcript_text if transcript_text else \"No transcript available\"\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m transcript_text \u001b[38;5;241m=\u001b[39m \u001b[43mget_transcript_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranscript\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m transcript_text\n\u001b[0;32m     42\u001b[0m comments \u001b[38;5;241m=\u001b[39m get_video_comments(API_KEY, vid)\n",
            "Cell \u001b[1;32mIn[10], line 26\u001b[0m, in \u001b[0;36mget_transcript_fallback\u001b[1;34m(video_id)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# 2Ô∏è‚É£ N·∫øu kh√¥ng c√≥, d√πng Whisper ƒë·ªÉ t·∫°o transcript t·ª´ audio\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m audio_path \u001b[38;5;241m=\u001b[39m \u001b[43mget_audio_from_youtube\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# text = transcribe_audio_whisper(audio_path)\u001b[39;00m\n\u001b[0;32m     28\u001b[0m text \u001b[38;5;241m=\u001b[39m transcribe_audio_local(audio_path)\n",
            "Cell \u001b[1;32mIn[10], line 3\u001b[0m, in \u001b[0;36mget_audio_from_youtube\u001b[1;34m(video_id, output_path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_audio_from_youtube\u001b[39m(video_id, output_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemp_audio.mp3\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      2\u001b[0m     yt \u001b[38;5;241m=\u001b[39m YouTube(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.youtube.com/watch?v=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvideo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m     audio_stream \u001b[38;5;241m=\u001b[39m \u001b[43myt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstreams\u001b[49m\u001b[38;5;241m.\u001b[39mfilter(only_audio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mfirst()\n\u001b[0;32m      4\u001b[0m     audio_stream\u001b[38;5;241m.\u001b[39mdownload(filename\u001b[38;5;241m=\u001b[39moutput_path)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output_path\n",
            "File \u001b[1;32mc:\\Users\\quocla\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytube\\__main__.py:296\u001b[0m, in \u001b[0;36mYouTube.streams\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Interface to query both adaptive (DASH) and progressive streams.\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \n\u001b[0;32m    293\u001b[0m \u001b[38;5;124;03m:rtype: :class:`StreamQuery <StreamQuery>`.\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_availability()\n\u001b[1;32m--> 296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m StreamQuery(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmt_streams\u001b[49m)\n",
            "File \u001b[1;32mc:\\Users\\quocla\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytube\\__main__.py:176\u001b[0m, in \u001b[0;36mYouTube.fmt_streams\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fmt_streams\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fmt_streams \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 176\u001b[0m stream_manifest \u001b[38;5;241m=\u001b[39m extract\u001b[38;5;241m.\u001b[39mapply_descrambler(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstreaming_data\u001b[49m)\n\u001b[0;32m    178\u001b[0m \u001b[38;5;66;03m# If the cached js doesn't work, try fetching a new js file\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;66;03m# https://github.com/pytube/pytube/issues/1054\u001b[39;00m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\quocla\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytube\\__main__.py:157\u001b[0m, in \u001b[0;36mYouTube.streaming_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstreaming_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    156\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return streamingData from video info.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstreamingData\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvid_info\u001b[49m:\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvid_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstreamingData\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\quocla\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytube\\__main__.py:246\u001b[0m, in \u001b[0;36mYouTube.vid_info\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vid_info\n\u001b[0;32m    244\u001b[0m innertube \u001b[38;5;241m=\u001b[39m InnerTube(use_oauth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_oauth, allow_cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallow_oauth_cache)\n\u001b[1;32m--> 246\u001b[0m innertube_response \u001b[38;5;241m=\u001b[39m \u001b[43minnertube\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplayer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvideo_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vid_info \u001b[38;5;241m=\u001b[39m innertube_response\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vid_info\n",
            "File \u001b[1;32mc:\\Users\\quocla\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytube\\innertube.py:448\u001b[0m, in \u001b[0;36mInnerTube.player\u001b[1;34m(self, video_id)\u001b[0m\n\u001b[0;32m    444\u001b[0m query \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideoId\u001b[39m\u001b[38;5;124m'\u001b[39m: video_id,\n\u001b[0;32m    446\u001b[0m }\n\u001b[0;32m    447\u001b[0m query\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_params)\n\u001b[1;32m--> 448\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_api\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_data\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\quocla\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytube\\innertube.py:390\u001b[0m, in \u001b[0;36mInnerTube._call_api\u001b[1;34m(self, endpoint, query, data)\u001b[0m\n\u001b[0;32m    386\u001b[0m         headers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAuthorization\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBearer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccess_token\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    388\u001b[0m headers\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheader)\n\u001b[1;32m--> 390\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mread())\n",
            "File \u001b[1;32mc:\\Users\\quocla\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytube\\request.py:37\u001b[0m, in \u001b[0;36m_execute_request\u001b[1;34m(url, method, headers, data, timeout)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid URL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\quocla\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\quocla\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[0;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "File \u001b[1;32mc:\\Users\\quocla\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[1;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "File \u001b[1;32mc:\\Users\\quocla\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[0;32m    562\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[1;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\quocla\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "File \u001b[1;32mc:\\Users\\quocla\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[1;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
            "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 400: Bad Request"
          ]
        }
      ],
      "source": [
        "# MAIN PIPELINE\n",
        "# ========================\n",
        "def main():\n",
        "    video_ids = get_videos_from_playlist(API_KEY, PLAYLIST_ID)\n",
        "    print(f\"üîπ Found {len(video_ids)} video in playlist\")\n",
        "\n",
        "    all_data = []\n",
        "\n",
        "    for idx, vid in enumerate(video_ids, 1):\n",
        "        print(f\"‚û°Ô∏è Crawl video {idx}/{len(video_ids)}: {vid}\")\n",
        "        video_info = get_video_info(API_KEY, vid)\n",
        "        if not video_info:\n",
        "            continue\n",
        "\n",
        "        snippet = video_info[\"snippet\"]\n",
        "        statistics = video_info.get(\"statistics\", {})\n",
        "        content_details = video_info.get(\"contentDetails\", {})\n",
        "\n",
        "        # Get data\n",
        "        data = {\n",
        "            \"video_id\": vid,\n",
        "            \"title\": snippet.get(\"title\"),\n",
        "            \"description\": snippet.get(\"description\"),\n",
        "            \"publishedAt\": snippet.get(\"publishedAt\"),\n",
        "            \"channelId\": snippet.get(\"channelId\"),\n",
        "            \"channelTitle\": snippet.get(\"channelTitle\"),\n",
        "            \"tags\": snippet.get(\"tags\", []),\n",
        "            \"viewCount\": statistics.get(\"viewCount\"),\n",
        "            \"likeCount\": statistics.get(\"likeCount\"),\n",
        "            \"commentCount\": statistics.get(\"commentCount\"),\n",
        "            \"duration\": content_details.get(\"duration\"),\n",
        "            \"caption\": content_details.get(\"caption\"),\n",
        "        }\n",
        "\n",
        "        transcript_text = get_transcript(vid)\n",
        "        data[\"transcript\"] = transcript_text if transcript_text else \"No transcript available\"\n",
        "\n",
        "        # transcript_text = get_transcript_fallback(vid)\n",
        "        # data[\"transcript\"] = transcript_text\n",
        "\n",
        "\n",
        "        comments = get_video_comments(API_KEY, vid)\n",
        "        data[\"comments\"] = comments if comments else []\n",
        "\n",
        "        all_data.append(data)\n",
        "\n",
        "    # Create folder to save data by date\n",
        "    # ========================\n",
        "    today = datetime.today().strftime(\"%Y-%m-%d\")\n",
        "    save_dir = os.path.join(\"data\", today)\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    json_path = os.path.join(save_dir, \"playlist_data.json\")\n",
        "    csv_path = os.path.join(save_dir, \"playlist_data.csv\")\n",
        "\n",
        "    # Save JSON\n",
        "    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(all_data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "    # Save CSV\n",
        "    if all_data:\n",
        "        keys = all_data[0].keys()\n",
        "        with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "            writer = csv.DictWriter(f, fieldnames=keys)\n",
        "            writer.writeheader()\n",
        "            writer.writerows(all_data)\n",
        "\n",
        "    print(f\"‚úÖ Saved data in folder: {save_dir}\")\n",
        "\n",
        "    # # Save JSON\n",
        "    # with open(\"playlist_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    #     json.dump(all_data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "    # # Save CSV\n",
        "    # keys = all_data[0].keys() if all_data else []\n",
        "    # with open(\"playlist_data.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "    #     writer = csv.DictWriter(f, fieldnames=keys)\n",
        "    #     writer.writeheader()\n",
        "    #     writer.writerows(all_data)\n",
        "\n",
        "    # print(\"‚úÖ Saved playlist_data.json and playlist_data.csv\")\n",
        "\n",
        "    # Specify the destination folder in your Google Drive -----\n",
        "    # drive_save_dir = os.path.join('/content/drive/My Drive/Research/Brand Image Detection/Code', save_dir)\n",
        "\n",
        "    # # Create the directory in Google Drive if it doesn't exist\n",
        "    # os.makedirs(drive_save_dir, exist_ok=True)\n",
        "\n",
        "    # # Copy the saved files to Google Drive\n",
        "    # shutil.copy(json_path, drive_save_dir)\n",
        "    # shutil.copy(csv_path, drive_save_dir)\n",
        "\n",
        "    # print(f\"‚úÖ Copied data to Google Drive folder: {drive_save_dir}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Th·ª≠ l·∫•y transcript speech-to-text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2025.10.22-py3-none-any.whl.metadata (176 kB)\n",
            "Requirement already satisfied: openai-whisper in c:\\users\\quocla\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (20250625)\n",
            "Requirement already satisfied: torch in c:\\users\\quocla\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.7.1)\n",
            "Requirement already satisfied: more-itertools in c:\\users\\quocla\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai-whisper) (10.6.0)\n",
            "Requirement already satisfied: numba in c:\\users\\quocla\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai-whisper) (0.62.1)\n",
            "Requirement already satisfied: numpy in c:\\users\\quocla\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai-whisper) (1.26.4)\n",
            "Requirement already satisfied: tiktoken in c:\\users\\quocla\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai-whisper) (0.12.0)\n",
            "Requirement already satisfied: tqdm in c:\\users\\quocla\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\quocla\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\quocla\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\quocla\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx in c:\\users\\quocla\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\quocla\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in c:\\users\\quocla\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\quocla\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\quocla\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in c:\\users\\quocla\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from numba->openai-whisper) (0.45.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\quocla\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in c:\\users\\quocla\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\quocla\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\quocla\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\quocla\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\quocla\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.8.3)\n",
            "Requirement already satisfied: colorama in c:\\users\\quocla\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->openai-whisper) (0.4.6)\n",
            "Downloading yt_dlp-2025.10.22-py3-none-any.whl (3.2 MB)\n",
            "   ---------------------------------------- 0.0/3.2 MB ? eta -:--:--\n",
            "   ------------------- -------------------- 1.6/3.2 MB 8.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 3.2/3.2 MB 10.6 MB/s  0:00:00\n",
            "Installing collected packages: yt-dlp\n",
            "Successfully installed yt-dlp-2025.10.22\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  WARNING: The script yt-dlp.exe is installed in 'c:\\Users\\quocla\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "pip install yt-dlp openai-whisper torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from yt_dlp import YoutubeDL\n",
        "import whisper\n",
        "\n",
        "def download_and_transcribe_local_whisper(video_url, output_filename=\"temp_audio.mp3\", model_name=\"base\"):\n",
        "    \"\"\"\n",
        "    T·∫£i lu·ªìng √¢m thanh v√† s·ª≠ d·ª•ng m√¥ h√¨nh Whisper c·ª•c b·ªô ƒë·ªÉ l·∫•y transcript.\n",
        "    \n",
        "    Args:\n",
        "        video_url (str): Link YouTube c·∫ßn x·ª≠ l√Ω.\n",
        "        output_filename (str): T√™n file √¢m thanh t·∫°m th·ªùi.\n",
        "        model_name (str): K√≠ch th∆∞·ªõc m√¥ h√¨nh Whisper ('tiny', 'base', 'small', 'medium', 'large').\n",
        "                          'base' l√† s·ª± c√¢n b·∫±ng t·ªët gi·ªØa t·ªëc ƒë·ªô v√† ƒë·ªô ch√≠nh x√°c.\n",
        "                          'medium' ho·∫∑c 'large' cho ƒë·ªô ch√≠nh x√°c cao nh·∫•t (nh∆∞ng ch·∫≠m h∆°n).\n",
        "                          \n",
        "    Returns:\n",
        "        str: Transcript ho√†n ch·ªânh ho·∫∑c th√¥ng b√°o l·ªói.\n",
        "    \"\"\"\n",
        "    print(f\"--- B∆Ø·ªöC 1: T·∫£i xu·ªëng lu·ªìng √¢m thanh ({output_filename}) ---\")\n",
        "    \n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'postprocessors': [{'key': 'FFmpegExtractAudio', 'preferredcodec': 'mp3', 'preferredquality': '192',}],\n",
        "        'outtmpl': output_filename,\n",
        "        'quiet': True,\n",
        "        'noprogress': True,\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # T·∫£i xu·ªëng\n",
        "        with YoutubeDL(ydl_opts) as ydl:\n",
        "            ydl.download([video_url])\n",
        "        print(\"‚úÖ T·∫£i xu·ªëng th√†nh c√¥ng.\")\n",
        "        \n",
        "        # Ki·ªÉm tra v√† ƒëi·ªÅu ch·ªânh t√™n file (ƒë√¥i khi yt-dlp th√™m extension)\n",
        "        if not os.path.exists(output_filename):\n",
        "            downloaded_file = next((f for f in os.listdir('.') if f.startswith('temp_audio')), None)\n",
        "            if downloaded_file:\n",
        "                os.rename(downloaded_file, output_filename)\n",
        "            else:\n",
        "                return \"L·ªói: Kh√¥ng t√¨m th·∫•y file √¢m thanh ƒë√£ t·∫£i.\"\n",
        "\n",
        "        print(f\"--- B∆Ø·ªöC 2: T·∫£i v√† Ch·∫°y m√¥ h√¨nh Whisper '{model_name}' tr√™n m√°y c·ª•c b·ªô ---\")\n",
        "        \n",
        "        # T·∫£i m√¥ h√¨nh (s·∫Ω t·ª± ƒë·ªông t·∫£i xu·ªëng l·∫ßn ƒë·∫ßu ti√™n)\n",
        "        model = whisper.load_model(model_name)\n",
        "        \n",
        "        # Chuy·ªÉn ƒë·ªïi gi·ªçng n√≥i th√†nh vƒÉn b·∫£n\n",
        "        result = model.transcribe(output_filename)\n",
        "        \n",
        "        print(\"‚úÖ Chuy·ªÉn ƒë·ªïi th√†nh c√¥ng.\")\n",
        "        \n",
        "        return result[\"text\"]\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"ƒê√£ x·∫£y ra l·ªói trong qu√° tr√¨nh x·ª≠ l√Ω: {e}\"\n",
        "    \n",
        "    finally:\n",
        "        # --- B∆Ø·ªöC 3: D·ªçn d·∫πp ---\n",
        "        if os.path.exists(output_filename):\n",
        "            os.remove(output_filename)\n",
        "            print(f\"üóëÔ∏è ƒê√£ x√≥a file t·∫°m: {output_filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- B∆Ø·ªöC 1: T·∫£i xu·ªëng lu·ªìng √¢m thanh (temp_audio.mp3) ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: [youtube] Falling back to generic n function search\n",
            "         player = https://www.youtube.com/s/player/c6d7bdc9/player_ias.vflset/en_US/base.js\n",
            "WARNING: [youtube] PEF-Fm_qlLM: nsig extraction failed: Some formats may be missing\n",
            "         n = kINb_lSvg4gm5h3B ; player = https://www.youtube.com/s/player/c6d7bdc9/player_ias.vflset/en_US/base.js\n",
            "         Please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
            "WARNING: [youtube] PEF-Fm_qlLM: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
            "WARNING: [youtube] PEF-Fm_qlLM: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
            "WARNING: PEF-Fm_qlLM: writing DASH m4a. Only some players support this container. Install ffmpeg to fix this automatically\n",
            "ERROR: Postprocessing: ffprobe and ffmpeg not found. Please install or provide the path using --ffmpeg-location\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üóëÔ∏è ƒê√£ x√≥a file t·∫°m: temp_audio.mp3\n",
            "\n",
            "--- K·∫æT QU·∫¢ TRANSCRIPT T·ª™ WHISPER LOKAL ---\n",
            "ƒê√£ x·∫£y ra l·ªói trong qu√° tr√¨nh x·ª≠ l√Ω: ERROR: Postprocessing: ffprobe and ffmpeg not found. Please install or provide the path using --ffmpeg-location\n"
          ]
        }
      ],
      "source": [
        "# --- S·ª¨ D·ª§NG ---\n",
        "video_link = \"https://www.youtube.com/watch?v=PEF-Fm_qlLM\" \n",
        "# Ch·ªçn 'base' (c√¢n b·∫±ng) ho·∫∑c 'small' (ch·∫≠m h∆°n nh∆∞ng ch√≠nh x√°c h∆°n)\n",
        "# https://www.youtube.com/watch?v=IM8lTK9Jbco&list=PLqFfyQGXEX5rC-BKJpLY67PT3lDh684M0&index=1\n",
        "# https://www.youtube.com/watch?v=PEF-Fm_qlLM&list=PLqFfyQGXEX5rC-BKJpLY67PT3lDh684M0&index=2\n",
        "model_to_use = \"base\" \n",
        "\n",
        "full_transcript = download_and_transcribe_local_whisper(video_link, model_name=model_to_use)\n",
        "\n",
        "print(\"\\n--- K·∫æT QU·∫¢ TRANSCRIPT T·ª™ WHISPER LOKAL ---\")\n",
        "print(full_transcript)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
